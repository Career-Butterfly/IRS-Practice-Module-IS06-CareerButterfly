
      
      <!----><div class="ac-container ac-adaptiveCard" style=""><div class="ac-textBlock" style=""><p>Certainly! In a nutshell, <strong>XLM-T</strong> is a <strong>multilingual language model toolkit</strong> specifically designed for Twitter data. It builds upon the XLM-Roberta base and continues pre-training on a large corpus of Twitter content in multiple languages. <a href="https://github.com/cardiffnlp/xlm-t" class="tooltip-target" data-citationid="2c577b5f-36df-d092-3c5b-71226d24da6a-5-group" h="ID=SERP,5026.1">The resulting masked language model, known as <strong>twitter-xlm-roberta-base</strong>, can be downloaded from the Hugging Face hub</a><a href="https://github.com/cardiffnlp/xlm-t" class="ac-anchor sup-target" target="_blank" data-citationid="2c577b5f-36df-d092-3c5b-71226d24da6a-5" aria-label="1: twitter-xlm-roberta-base" h="ID=SERP,5026.1"><sup class="citation-sup">1</sup></a>.</p>
<p>Here are <strong>five free reference links</strong> where you can learn more about XLM-T and explore its capabilities:</p>
<ol>
<li>
<p><strong>GitHub Repository for XLM-T</strong>: This repository contains data, code, and pre-trained multilingual language models for Twitter. <a href="https://github.com/cardiffnlp/xlm-t" class="tooltip-target" data-citationid="2c577b5f-36df-d092-3c5b-71226d24da6a-14-group" h="ID=SERP,5026.1">Youâ€™ll find the XLM-T language model trained on 200M tweets for 30+ languages here: </a><a href="https://github.com/cardiffnlp/xlm-t" class="ac-anchor" target="_blank" is="cib-link" appearance="system-link" h="ID=SERP,5026.1">XLM-T GitHub Repository</a><a href="https://github.com/cardiffnlp/xlm-t" class="ac-anchor sup-target" target="_blank" data-citationid="2c577b5f-36df-d092-3c5b-71226d24da6a-14" aria-label="1: XLM-T GitHub Repository" h="ID=SERP,5026.1"><sup class="citation-sup">1</sup></a>.</p>
</li>
<li>
<p><a href="https://github.com/cardiffnlp/xlm-t" class="tooltip-target" data-citationid="2c577b5f-36df-d092-3c5b-71226d24da6a-20-group" h="ID=SERP,5026.1"><strong>Reference Paper</strong>: Dive into the details of XLM-T by referring to the research paper that explains its methodology and development: </a><a href="https://github.com/cardiffnlp/xlm-t" class="ac-anchor" target="_blank" is="cib-link" appearance="system-link" h="ID=SERP,5026.1">XLM-T Reference Paper</a><a href="https://github.com/cardiffnlp/xlm-t" class="ac-anchor sup-target" target="_blank" data-citationid="2c577b5f-36df-d092-3c5b-71226d24da6a-20" aria-label="1: XLM-T Reference Paper" h="ID=SERP,5026.1"><sup class="citation-sup">1</sup></a>.</p>
</li>
<li>
<p><strong>TweetEval Framework</strong>: Explore the English-only counterpart of XLM-T, which was introduced as part of the TweetEval framework. <a href="https://github.com/cardiffnlp/xlm-t" class="tooltip-target" data-citationid="2c577b5f-36df-d092-3c5b-71226d24da6a-26-group" h="ID=SERP,5026.1">This framework includes various tweet classification tasks and provides valuable insights: </a><a href="https://github.com/cardiffnlp/xlm-t" class="ac-anchor" target="_blank" is="cib-link" appearance="system-link" h="ID=SERP,5026.1">TweetEval Framework</a><a href="https://github.com/cardiffnlp/xlm-t" class="ac-anchor sup-target" target="_blank" data-citationid="2c577b5f-36df-d092-3c5b-71226d24da6a-26" aria-label="1: TweetEval Framework" h="ID=SERP,5026.1"><sup class="citation-sup">1</sup></a>.</p>
</li>
<li>
<p><strong>Colab Notebooks for Prototyping</strong>: For quick prototyping and experimentation, check out the Colab notebooks provided by the XLM-T team. <a href="https://github.com/cardiffnlp/xlm-t" class="tooltip-target" data-citationid="2c577b5f-36df-d092-3c5b-71226d24da6a-32-group" h="ID=SERP,5026.1">These notebooks cover topics like feature extraction, sentiment prediction, and fine-tuning: </a><a href="https://github.com/cardiffnlp/xlm-t" class="ac-anchor" target="_blank" is="cib-link" appearance="system-link" h="ID=SERP,5026.1">XLM-T Colab Notebooks</a><a href="https://github.com/cardiffnlp/xlm-t" class="ac-anchor sup-target" target="_blank" data-citationid="2c577b5f-36df-d092-3c5b-71226d24da6a-32" aria-label="1: XLM-T Colab Notebooks" h="ID=SERP,5026.1"><sup class="citation-sup">1</sup></a>.</p>
</li>
<li>
<p><strong>Huggingface Pipelines</strong>: Learn how to perform inference using Huggingfaceâ€™s pipelines with XLM-T. <a href="https://github.com/cardiffnlp/xlm-t" class="tooltip-target" data-citationid="2c577b5f-36df-d092-3c5b-71226d24da6a-38-group" h="ID=SERP,5026.1">The provided examples demonstrate sentiment analysis on Twitter text: </a><a href="https://github.com/cardiffnlp/xlm-t" class="ac-anchor" target="_blank" is="cib-link" appearance="system-link" h="ID=SERP,5026.1">Huggingface Pipelines with XLM-T</a><a href="https://github.com/cardiffnlp/xlm-t" class="ac-anchor sup-target" target="_blank" data-citationid="2c577b5f-36df-d092-3c5b-71226d24da6a-38" aria-label="1: Huggingface Pipelines with XLM-T" h="ID=SERP,5026.1"><sup class="citation-sup">1</sup></a>.</p>
</li>
</ol>
<p>Feel free to explore these resources to deepen your understanding of XLM-T and its applications! ðŸš€</p>
</div><div class="ac-horizontal-separator" aria-hidden="true" style=""></div></div>
      <div class="ad-container"> </div>
      
      <cib-overlay>
        
      </cib-overlay>
    